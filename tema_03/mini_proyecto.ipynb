{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:47:32.546998: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-25 20:47:33.177196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "from time import perf_counter\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso 1\n",
    "\n",
    "def get_datos():\n",
    "    datos=[[  2.01666708 ,  56.18031474], [  4.79734083 ,  47.18848199], [  9.23784581 ,  57.68974048], [ 14.11529384 ,  43.70348368],\n",
    "         [ 14.92688637 ,  59.10244323], [ 17.34408196 ,  65.96080804], [ 17.62435324 ,  45.74334603], [ 22.41875021 ,  13.575581  ],\n",
    "         [ 25.3139145  ,  68.43756969], [ 34.85886672 , 147.15375307], [ 38.87476262 ,  25.39687009], [ 42.01380169 ,  74.39010069],\n",
    "         [ 46.63551059 ,  98.93395801], [ 49.58578273 , 116.07013679], [ 50.18371003 , 138.55546747], [ 52.06630172 , 139.36601894],\n",
    "         [ 54.68810274 , 150.09622546], [ 57.13046193 , 156.14375739], [ 66.35609935 , 119.75844452], [ 69.05499042 , 139.08155228],\n",
    "         [ 69.51252436 , 128.72247348], [ 69.83788756 , 152.65110462], [ 79.76649746 , 148.23106977], [ 81.83730552 , 137.86314926],\n",
    "         [ 87.09879038 , 217.28932067], [ 89.00469759 , 168.64994509], [ 93.17139213 , 163.10598352], [ 93.66070686 , 200.47638924],\n",
    "         [ 94.1944751  , 150.44019156], [ 97.36920633 , 173.2055957 ]]\n",
    "\n",
    "    return datos\n",
    "\n",
    "\n",
    "datos=np.array(get_datos())\n",
    "\n",
    "x_entrenamiento=datos[:,0].reshape(-1,1)\n",
    "y_entrenamiento=datos[:,1].reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/logongas/Documentos/desarrollo/python_default_env/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-11-25 20:47:34.186536: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "#Paso 2\n",
    "def compile_fit(capas,x,y,epochs):\n",
    "    np.random.seed(5)\n",
    "    tf.random.set_seed(5)\n",
    "    random.seed(5)  \n",
    "    \n",
    "    model=Sequential()\n",
    "    for index,neuronas_capa in enumerate(capas):\n",
    "        if (index==0):\n",
    "            model.add(Dense(neuronas_capa, activation='relu',input_dim=x.shape[1]))\n",
    "        elif (index==len(capas)-1):\n",
    "            model.add(Dense(neuronas_capa, activation='linear'))\n",
    "        else:\n",
    "            model.add(Dense(neuronas_capa, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error')\n",
    "    \n",
    "    history=model.fit(x, y,epochs=epochs,verbose=False) \n",
    "\n",
    "    return model,history\n",
    "\n",
    "capas=[5,10,3,10,1]\n",
    "epochs=5000\n",
    "model,history=compile_fit(capas,x_entrenamiento,y_entrenamiento,epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       x    y_true    y_pred     error\n",
      "--------  --------  --------  --------\n",
      " 2.01667   56.1803   36.755   377.341\n",
      " 4.79734   47.1885   41.127    36.7413\n",
      " 9.23785   57.6897   48.1087   91.7958\n",
      "14.1153    43.7035   55.7774  145.78\n"
     ]
    }
   ],
   "source": [
    "#Paso 3\n",
    "\n",
    "x_paso3=np.array([ 2.01666708, 4.79734083, 9.23784581, 14.11529384 ]).reshape(-1,1)\n",
    "y_true_paso3=np.array([ 56.18031474, 47.18848199, 57.68974048, 43.70348368]).reshape(-1,1)\n",
    "y_pred_paso3=model.predict(x_paso3,verbose=False)\n",
    "y_error_paso3=(y_true_paso3-y_pred_paso3)**2\n",
    "\n",
    "resultado_paso3=np.column_stack((x_paso3,y_true_paso3,y_pred_paso3,y_error_paso3))\n",
    "\n",
    "print(tabulate(resultado_paso3,headers=[\"x\",\"y_true\",\"y_pred\",\"error\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE)=162.915\n"
     ]
    }
   ],
   "source": [
    "#Paso 4\n",
    "\n",
    "mse=np.sum(y_error_paso3)/np.size(y_error_paso3)\n",
    "print(f\"Mean Squared Error (MSE)={mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente de determinación o R²=-3.681\n"
     ]
    }
   ],
   "source": [
    "#Paso 5\n",
    "media_valores_verdaderos=np.sum(y_true_paso3)/np.size(y_true_paso3)\n",
    "suma_errores=np.sum((y_true_paso3-y_pred_paso3)**2)\n",
    "suma_valores_media=np.sum((y_true_paso3-media_valores_verdaderos)**2)\n",
    "coeficiente_determinacion=1-(suma_errores/suma_valores_media)\n",
    "\n",
    "print(f\"Coeficiente de determinación o R²={coeficiente_determinacion:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE)=720.424\n",
      "Coeficiente de determinación o R²=0.748\n"
     ]
    }
   ],
   "source": [
    "#Paso 6\n",
    "def get_mse(y_true,y_pred):\n",
    "    y_error=(y_true-y_pred)**2\n",
    "    mse=np.sum(y_error)/np.size(y_error)\n",
    "\n",
    "    return mse\n",
    "\n",
    "def get_coeficiente_determinacion(y_true,y_pred):\n",
    "    media_valores_verdaderos=np.sum(y_true)/np.size(y_true)\n",
    "    suma_errores=np.sum((y_true-y_pred)**2)\n",
    "    suma_valores_media=np.sum((y_true-media_valores_verdaderos)**2)\n",
    "    coeficiente_determinacion=1-(suma_errores/suma_valores_media)\n",
    "\n",
    "    return coeficiente_determinacion\n",
    "\n",
    "\n",
    "def get_metricas_modelo(model,x,y_true):\n",
    "    y_pred=model.predict(x,verbose=False)\n",
    "    mse=get_mse(y_true,y_pred)\n",
    "    coeficiente_determinacion=get_coeficiente_determinacion(y_true,y_pred)\n",
    "\n",
    "    return mse,coeficiente_determinacion\n",
    "\n",
    "mse,coeficiente_determinacion=get_metricas_modelo(model,x_entrenamiento,y_entrenamiento)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE)={mse:.3f}\")\n",
    "print(f\"Coeficiente de determinación o R²={coeficiente_determinacion:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE)=479.729\n",
      "Coeficiente de determinación o R²=0.832\n"
     ]
    }
   ],
   "source": [
    "#Paso 7\n",
    "capas=[20,40,80,40,20,1]\n",
    "model,history=compile_fit(capas,x_entrenamiento,y_entrenamiento,epochs)\n",
    "mse,coeficiente_determinacion=get_metricas_modelo(model,x_entrenamiento,y_entrenamiento)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE)={mse:.3f}\")\n",
    "print(f\"Coeficiente de determinación o R²={coeficiente_determinacion:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE)=214.376\n",
      "Coeficiente de determinación o R²=0.925\n"
     ]
    }
   ],
   "source": [
    "#Paso 8\n",
    "\n",
    "def compile_fit(capas,x,y,epochs,activation):\n",
    "    np.random.seed(5)\n",
    "    tf.random.set_seed(5)\n",
    "    random.seed(5)  \n",
    "    \n",
    "    model=Sequential()\n",
    "    for index,neuronas_capa in enumerate(capas):\n",
    "        if (index==0):\n",
    "            model.add(Dense(neuronas_capa, activation=activation,input_dim=x.shape[1]))\n",
    "        elif (index==len(capas)-1):\n",
    "            model.add(Dense(neuronas_capa, activation='linear'))\n",
    "        else:\n",
    "            model.add(Dense(neuronas_capa, activation=activation))\n",
    "    model.compile(loss='mean_squared_error')\n",
    "    \n",
    "    history=model.fit(x, y,epochs=epochs,verbose=False) \n",
    "\n",
    "    return model,history\n",
    "\n",
    "\n",
    "\n",
    "capas=[20,40,80,40,20,1]\n",
    "model,history=compile_fit(capas,x_entrenamiento,y_entrenamiento,epochs,\"selu\")\n",
    "mse,coeficiente_determinacion=get_metricas_modelo(model,x_entrenamiento,y_entrenamiento)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE)={mse:.3f}\")\n",
    "print(f\"Coeficiente de determinación o R²={coeficiente_determinacion:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x760acc274f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x760acd33dd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "  Nombre  Capas                               Épocas  Activación         MSE           R²           Tiempo\n",
      "     Red                                                                                     Entrenamiento\n",
      "--------  --------------------------------  --------  ------------  --------  -----------  ---------------\n",
      "       1  [5, 10, 30, 10, 1]                    5000  relu           699.618   0.754861            62.19\n",
      "       2  [5, 10, 30, 10, 1]                    5000  selu           565.859   0.801729            62.5378\n",
      "       3  [5, 10, 30, 10, 1]                    5000  tanh          5790.5    -1.02893             62.5708\n",
      "       4  [20, 40, 80, 40, 20, 1]               5000  relu           479.729   0.831908            60.9812\n",
      "       5  [20, 40, 80, 40, 20, 1]               5000  selu           214.376   0.924885            59.9829\n",
      "       6  [20, 40, 80, 40, 20, 1]               5000  tanh          2869.38   -0.00540068          57.5197\n",
      "       7  [20, 40, 80, 160, 80, 40, 20, 1]      5000  relu           385.477   0.864933            59.9699\n",
      "       8  [20, 40, 80, 160, 80, 40, 20, 1]      5000  selu           149.003   0.947791            67.2952\n",
      "       9  [20, 40, 80, 160, 80, 40, 20, 1]      5000  tanh          2870.34   -0.00573854          64.2257\n"
     ]
    }
   ],
   "source": [
    "#Paso 9\n",
    "\n",
    "def compile_fit(capas,x,y,epochs,activation):\n",
    "    np.random.seed(5)\n",
    "    tf.random.set_seed(5)\n",
    "    random.seed(5)  \n",
    "    \n",
    "    model=Sequential()\n",
    "    for index,neuronas_capa in enumerate(capas):\n",
    "        if (index==0):\n",
    "            model.add(Dense(neuronas_capa, activation=activation,input_dim=x.shape[1]))\n",
    "        elif (index==len(capas)-1):\n",
    "            model.add(Dense(neuronas_capa, activation='linear'))\n",
    "        else:\n",
    "            model.add(Dense(neuronas_capa, activation=activation))\n",
    "    model.compile(loss='mean_squared_error')\n",
    "    \n",
    "    tiempo_entrenamiento = perf_counter()\n",
    "    history=model.fit(x, y,epochs=epochs,verbose=False) \n",
    "    tiempo_entrenamiento=perf_counter()-tiempo_entrenamiento\n",
    "\n",
    "    return model,history,tiempo_entrenamiento\n",
    "\n",
    "redes_neuronales=[\n",
    "    [[5,10,30,10,1],\"relu\"],\n",
    "    [[5,10,30,10,1],\"selu\"],\n",
    "    [[5,10,30,10,1],\"tanh\"],    \n",
    "    [[20,40,80,40,20,1],\"relu\"],\n",
    "    [[20,40,80,40,20,1],\"selu\"],\n",
    "    [[20,40,80,40,20,1],\"tanh\"],\n",
    "    [[20,40,80,160,80,40,20,1],\"relu\"],\n",
    "    [[20,40,80,160,80,40,20,1],\"selu\"],\n",
    "    [[20,40,80,160,80,40,20,1],\"tanh\"]                           \n",
    "]\n",
    "epochs=5000\n",
    "\n",
    "resultados=[]\n",
    "\n",
    "for index,(capas,activacion) in enumerate(redes_neuronales):\n",
    "\n",
    "    model,history,tiempo_entrenamiento=compile_fit(capas,x_entrenamiento,y_entrenamiento,epochs,activacion)\n",
    "    mse_entrenamiento,coeficiente_determinacion_entrenamiento=get_metricas_modelo(model,x_entrenamiento,y_entrenamiento)\n",
    "\n",
    "    resultado=[str(index+1),str(capas),epochs,activacion,mse_entrenamiento,coeficiente_determinacion_entrenamiento,tiempo_entrenamiento]\n",
    "    resultados.append(resultado)\n",
    "\n",
    "print(tabulate(resultados,headers=[\"Nombre\\nRed\",\"Capas\",\"Épocas\",\"Activación\",\"MSE\",\"R²\",\"Tiempo\\nEntrenamiento\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nombre  Capas                               Épocas  Activación                MSE               R²           Tiempo           MSE            R²\n",
      "     Red                                                              Entrenamiento    Entrenamiento    Entrenamiento    Validación    Validación\n",
      "--------  --------------------------------  --------  ------------  ---------------  ---------------  ---------------  ------------  ------------\n",
      "       1  [5, 10, 30, 10, 1]                    5000  relu                  699.618       0.754861            62.5292       844.235     0.57673\n",
      "       2  [5, 10, 30, 10, 1]                    5000  selu                  565.859       0.801729            63.7465       841.22      0.578241\n",
      "       3  [5, 10, 30, 10, 1]                    5000  tanh                 5790.5        -1.02893             61.2735      3639.78     -0.82486\n",
      "       4  [20, 40, 80, 40, 20, 1]               5000  relu                  479.729       0.831908            63.8758       998.912     0.49918\n",
      "       5  [20, 40, 80, 40, 20, 1]               5000  selu                  214.376       0.924885            62.6622       766.595     0.615656\n",
      "       6  [20, 40, 80, 40, 20, 1]               5000  tanh                 2869.38       -0.00540068          61.9383      2088.69     -0.0471974\n",
      "       7  [20, 40, 80, 160, 80, 40, 20, 1]      5000  relu                  385.477       0.864933            63.9857       860.281     0.568685\n",
      "       8  [20, 40, 80, 160, 80, 40, 20, 1]      5000  selu                  149.003       0.947791            62.8397      1069.86      0.463611\n",
      "       9  [20, 40, 80, 160, 80, 40, 20, 1]      5000  tanh                 2870.34       -0.00573854          62.5369      2086.36     -0.0460281\n"
     ]
    }
   ],
   "source": [
    "#Paso 10\n",
    "def get_datos_validacion():\n",
    "    datos_validacion=[[  1.22140488 , 59.35315077] , [  2.42834632 ,  3.50613409] , [  4.27529991 , 70.39938914] ,\n",
    "        [ 14.44651349 , 50.0606769 ] , [ 16.10795855 , 81.08562061] , [ 16.75024181 , 33.95365822] ,\n",
    "        [ 26.80487149 , 47.1495392 ] , [ 28.81517859 ,106.34919698] , [ 48.56698654 ,120.25398606] ,\n",
    "        [ 52.08015067 ,116.7993955 ] , [ 53.30646055 ,131.30936472] , [ 55.09968806 ,131.34281752] ,\n",
    "        [ 60.39615207 , 97.77483743] , [ 73.52487026 , 92.30645543] , [ 76.2771471  ,109.9995226 ] ,\n",
    "        [ 84.56808303 ,120.60657657] , [ 89.2700557  ,117.3687155 ] , [ 91.03720679 ,159.47376137] ,\n",
    "        [ 93.53406333 ,166.44439331] , [ 94.78103495 ,180.66942656]]\n",
    "    return datos_validacion\n",
    "\n",
    "datos_validacion=np.array(get_datos_validacion())\n",
    "x_validacion=datos_validacion[:,0].reshape(-1,1)\n",
    "y_validacion=datos_validacion[:,1].reshape(-1,1)\n",
    "\n",
    "\n",
    "resultados=[]\n",
    "\n",
    "for index,(capas,activacion) in enumerate(redes_neuronales):\n",
    "\n",
    "    model,history,tiempo_entrenamiento=compile_fit(capas,x_entrenamiento,y_entrenamiento,epochs,activacion)\n",
    "    mse_entrenamiento,coeficiente_determinacion_entrenamiento=get_metricas_modelo(model,x_entrenamiento,y_entrenamiento)\n",
    "    mse_validacion,coeficiente_determinacion_validacion=get_metricas_modelo(model,x_validacion,y_validacion)   \n",
    "\n",
    "    resultado=[str(index+1),str(capas),epochs,activacion,mse_entrenamiento,coeficiente_determinacion_entrenamiento,tiempo_entrenamiento,mse_validacion,coeficiente_determinacion_validacion]\n",
    "    resultados.append(resultado)\n",
    "\n",
    "print(tabulate(resultados,headers=[\"Nombre\\nRed\",\"Capas\",\"Épocas\",\"Activación\",\"MSE\\nEntrenamiento\",\"R²\\nEntrenamiento\",\"Tiempo\\nEntrenamiento\",\"MSE\\nValidación\",\"R²\\nValidación\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nombre  Capas                               Épocas  Activación                MSE               R²           Tiempo           MSE            R²\n",
      "     Red                                                              Entrenamiento    Entrenamiento    Entrenamiento    Validación    Validación\n",
      "--------  --------------------------------  --------  ------------  ---------------  ---------------  ---------------  ------------  ------------\n",
      "       1  [5, 10, 30, 10, 1]                    5000  relu                  699.618       0.754861            77.1727       844.235     0.57673\n",
      "       2  [5, 10, 30, 10, 1]                    5000  selu                  565.859       0.801729            76.1871       841.22      0.578241\n",
      "       3  [5, 10, 30, 10, 1]                    5000  tanh                 5790.5        -1.02893             75.9268      3639.78     -0.82486\n",
      "       4  [20, 40, 80, 40, 20, 1]               5000  relu                  479.729       0.831908            74.753        998.912     0.49918\n",
      "       5  [20, 40, 80, 40, 20, 1]               5000  selu                  214.376       0.924885            73.2869       766.595     0.615656\n",
      "       6  [20, 40, 80, 40, 20, 1]               5000  tanh                 2869.38       -0.00540068          73.7633      2088.69     -0.0471974\n",
      "       7  [20, 40, 80, 160, 80, 40, 20, 1]      5000  relu                  385.477       0.864933            74.9001       860.281     0.568685\n",
      "       8  [20, 40, 80, 160, 80, 40, 20, 1]      5000  selu                  149.003       0.947791            75.9712      1069.86      0.463611\n",
      "       9  [20, 40, 80, 160, 80, 40, 20, 1]      5000  tanh                 2870.34       -0.00573854          75.9561      2086.36     -0.0460281\n"
     ]
    }
   ],
   "source": [
    "#Paso 11\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "from time import perf_counter\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def get_datos():\n",
    "    datos=[[  2.01666708 ,  56.18031474], [  4.79734083 ,  47.18848199], [  9.23784581 ,  57.68974048], [ 14.11529384 ,  43.70348368],\n",
    "         [ 14.92688637 ,  59.10244323], [ 17.34408196 ,  65.96080804], [ 17.62435324 ,  45.74334603], [ 22.41875021 ,  13.575581  ],\n",
    "         [ 25.3139145  ,  68.43756969], [ 34.85886672 , 147.15375307], [ 38.87476262 ,  25.39687009], [ 42.01380169 ,  74.39010069],\n",
    "         [ 46.63551059 ,  98.93395801], [ 49.58578273 , 116.07013679], [ 50.18371003 , 138.55546747], [ 52.06630172 , 139.36601894],\n",
    "         [ 54.68810274 , 150.09622546], [ 57.13046193 , 156.14375739], [ 66.35609935 , 119.75844452], [ 69.05499042 , 139.08155228],\n",
    "         [ 69.51252436 , 128.72247348], [ 69.83788756 , 152.65110462], [ 79.76649746 , 148.23106977], [ 81.83730552 , 137.86314926],\n",
    "         [ 87.09879038 , 217.28932067], [ 89.00469759 , 168.64994509], [ 93.17139213 , 163.10598352], [ 93.66070686 , 200.47638924],\n",
    "         [ 94.1944751  , 150.44019156], [ 97.36920633 , 173.2055957 ]]\n",
    "\n",
    "    return datos\n",
    "\n",
    "def get_datos_validacion():\n",
    "    datos_validacion=[[  1.22140488 , 59.35315077] , [  2.42834632 ,  3.50613409] , [  4.27529991 , 70.39938914] ,\n",
    "        [ 14.44651349 , 50.0606769 ] , [ 16.10795855 , 81.08562061] , [ 16.75024181 , 33.95365822] ,\n",
    "        [ 26.80487149 , 47.1495392 ] , [ 28.81517859 ,106.34919698] , [ 48.56698654 ,120.25398606] ,\n",
    "        [ 52.08015067 ,116.7993955 ] , [ 53.30646055 ,131.30936472] , [ 55.09968806 ,131.34281752] ,\n",
    "        [ 60.39615207 , 97.77483743] , [ 73.52487026 , 92.30645543] , [ 76.2771471  ,109.9995226 ] ,\n",
    "        [ 84.56808303 ,120.60657657] , [ 89.2700557  ,117.3687155 ] , [ 91.03720679 ,159.47376137] ,\n",
    "        [ 93.53406333 ,166.44439331] , [ 94.78103495 ,180.66942656]]\n",
    "    return datos_validacion\n",
    "\n",
    "def compile_fit(capas,x,y,epochs,activation):\n",
    "    np.random.seed(5)\n",
    "    tf.random.set_seed(5)\n",
    "    random.seed(5)  \n",
    "    \n",
    "    model=Sequential()\n",
    "    for index,neuronas_capa in enumerate(capas):\n",
    "        if (index==0):\n",
    "            model.add(Dense(neuronas_capa, activation=activation,input_dim=x.shape[1]))\n",
    "        elif (index==len(capas)-1):\n",
    "            model.add(Dense(neuronas_capa, activation='linear'))\n",
    "        else:\n",
    "            model.add(Dense(neuronas_capa, activation=activation))\n",
    "    model.compile(loss='mean_squared_error',metrics=[\"r2_score\"])\n",
    "    \n",
    "    tiempo_entrenamiento = perf_counter()\n",
    "    history=model.fit(x, y,epochs=epochs,verbose=False) \n",
    "    tiempo_entrenamiento=perf_counter()-tiempo_entrenamiento\n",
    "\n",
    "    return model,history,tiempo_entrenamiento\n",
    "\n",
    "def get_mse(y_true,y_pred):\n",
    "    y_error=(y_true-y_pred)**2\n",
    "    mse=np.sum(y_error)/np.size(y_error)\n",
    "\n",
    "    return mse\n",
    "\n",
    "def get_coeficiente_determinacion(y_true,y_pred):\n",
    "    media_valores_verdaderos=np.sum(y_true)/np.size(y_true)\n",
    "    suma_errores=np.sum((y_true-y_pred)**2)\n",
    "    suma_valores_media=np.sum((y_true-media_valores_verdaderos)**2)\n",
    "    coeficiente_determinacion=1-(suma_errores/suma_valores_media)\n",
    "\n",
    "    return coeficiente_determinacion\n",
    "\n",
    "\n",
    "def get_metricas_modelo(model,x,y_true):\n",
    "    y_pred=model.predict(x,verbose=False)\n",
    "    mse=get_mse(y_true,y_pred)\n",
    "    coeficiente_determinacion=get_coeficiente_determinacion(y_true,y_pred)\n",
    "\n",
    "    return mse,coeficiente_determinacion\n",
    "\n",
    "\n",
    "datos=np.array(get_datos())\n",
    "x_entrenamiento=datos[:,0].reshape(-1,1)\n",
    "y_entrenamiento=datos[:,1].reshape(-1,1)\n",
    "\n",
    "datos_validacion=np.array(get_datos_validacion())\n",
    "x_validacion=datos_validacion[:,0].reshape(-1,1)\n",
    "y_validacion=datos_validacion[:,1].reshape(-1,1)\n",
    "\n",
    "\n",
    "redes_neuronales=[\n",
    "    [[5,10,30,10,1],\"relu\"],\n",
    "    [[5,10,30,10,1],\"selu\"],\n",
    "    [[5,10,30,10,1],\"tanh\"],    \n",
    "    [[20,40,80,40,20,1],\"relu\"],\n",
    "    [[20,40,80,40,20,1],\"selu\"],\n",
    "    [[20,40,80,40,20,1],\"tanh\"],\n",
    "    [[20,40,80,160,80,40,20,1],\"relu\"],\n",
    "    [[20,40,80,160,80,40,20,1],\"selu\"],\n",
    "    [[20,40,80,160,80,40,20,1],\"tanh\"]                           \n",
    "]\n",
    "epochs=5000\n",
    "\n",
    "resultados=[]\n",
    "\n",
    "for index,(capas,activacion) in enumerate(redes_neuronales):\n",
    "\n",
    "    model,history,tiempo_entrenamiento=compile_fit(capas,x_entrenamiento,y_entrenamiento,epochs,activacion)\n",
    "    mse_entrenamiento,coeficiente_determinacion_entrenamiento=get_metricas_modelo(model,x_entrenamiento,y_entrenamiento)\n",
    "    mse_validacion,coeficiente_determinacion_validacion=get_metricas_modelo(model,x_validacion,y_validacion)   \n",
    "\n",
    "    resultado=[str(index+1),str(capas),epochs,activacion,mse_entrenamiento,coeficiente_determinacion_entrenamiento,tiempo_entrenamiento,mse_validacion,coeficiente_determinacion_validacion]\n",
    "    resultados.append(resultado)  \n",
    "\n",
    "print(tabulate(resultados,headers=[\"Nombre\\nRed\",\"Capas\",\"Épocas\",\"Activación\",\"MSE\\nEntrenamiento\",\"R²\\nEntrenamiento\",\"Tiempo\\nEntrenamiento\",\"MSE\\nValidación\",\"R²\\nValidación\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/logongas/Documentos/desarrollo/python_default_env/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nombre  Capas                               Épocas  Activación                MSE               R²           Tiempo           MSE            R²\n",
      "     Red                                                              Entrenamiento    Entrenamiento    Entrenamiento    Validación    Validación\n",
      "--------  --------------------------------  --------  ------------  ---------------  ---------------  ---------------  ------------  ------------\n",
      "       1  [20, 1]                               1000  relu                 17.6675        0.796629            20.4627       19.3099     0.736684\n",
      "       2  [20, 1]                               1000  selu                 17.9466        0.793416            20.1527       20.5799     0.719366\n",
      "       3  [20, 1]                               1000  tanh                 56.1387        0.353787            20.3573       49.3726     0.326742\n",
      "       4  [20, 10, 1]                           1000  relu                 12.7836        0.852848            20.6068       18.3702     0.749499\n",
      "       5  [20, 10, 1]                           1000  selu                 16.5732        0.809226            20.0672       23.1573     0.684221\n",
      "       6  [20, 10, 1]                           1000  tanh                 25.2556        0.709283            19.8047       33.074      0.548994\n",
      "       7  [20, 30, 10, 1]                       1000  relu                  8.57789       0.90126             19.8473       14.975      0.795797\n",
      "       8  [20, 30, 10, 1]                       1000  selu                  7.2611        0.916417            19.2593       18.9803     0.74118\n",
      "       9  [20, 30, 10, 1]                       1000  tanh                 43.676         0.497245            19.2655       38.6584     0.472844\n",
      "      10  [20, 40, 80, 40, 20, 1]               1000  relu                 26.5718        0.694131            20.0258       43.7618     0.403251\n",
      "      11  [20, 40, 80, 40, 20, 1]               1000  selu                  6.08985       0.9299              20.2405       29.6259     0.596013\n",
      "      12  [20, 40, 80, 40, 20, 1]               1000  tanh                 45.6632        0.474371            20.0385       46.6583     0.363754\n",
      "      13  [20, 40, 80, 160, 80, 40, 20, 1]      1000  relu                  6.62845       0.9237              21.3596       24.4089     0.667154\n",
      "      14  [20, 40, 80, 160, 80, 40, 20, 1]      1000  selu                  3.42129       0.960618            21.5737       21.1846     0.711121\n",
      "      15  [20, 40, 80, 160, 80, 40, 20, 1]      1000  tanh                 86.8736       -2.5034e-06          21.545        75.0856    -0.0238887\n"
     ]
    }
   ],
   "source": [
    "def get_datos():\n",
    "    boston=fetch_openml(name=\"boston\",version=1)   \n",
    "    x=np.array(boston.data).astype(np.float32)\n",
    "    y=np.array(boston.target).astype(np.float32)\n",
    "\n",
    "    x_entrenamiento, x_validacion, y_entrenamiento, y_validacion = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return x_entrenamiento, y_entrenamiento.reshape(-1,1), x_validacion, y_validacion.reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "x_entrenamiento, y_entrenamiento, x_validacion, y_validacion=get_datos()\n",
    "\n",
    "redes_neuronales=[\n",
    "    [[20,1],\"relu\"],\n",
    "    [[20,1],\"selu\"],\n",
    "    [[20,1],\"tanh\"],       \n",
    "    [[20,10,1],\"relu\"],\n",
    "    [[20,10,1],\"selu\"],\n",
    "    [[20,10,1],\"tanh\"],        \n",
    "    [[20,30,10,1],\"relu\"],\n",
    "    [[20,30,10,1],\"selu\"],\n",
    "    [[20,30,10,1],\"tanh\"],  \n",
    "    [[20,40,80,40,20,1],\"relu\"],\n",
    "    [[20,40,80,40,20,1],\"selu\"],\n",
    "    [[20,40,80,40,20,1],\"tanh\"],\n",
    "    [[20,40,80,160,80,40,20,1],\"relu\"],\n",
    "    [[20,40,80,160,80,40,20,1],\"selu\"],\n",
    "    [[20,40,80,160,80,40,20,1],\"tanh\"]                               \n",
    "]                     \n",
    "\n",
    "epochs=1000\n",
    "\n",
    "resultados=[]\n",
    "\n",
    "\n",
    "\n",
    "for index,(capas,activacion) in enumerate(redes_neuronales):\n",
    "\n",
    "    model,history,tiempo_entrenamiento=compile_fit(capas,x_entrenamiento,y_entrenamiento,epochs,activacion)\n",
    "    mse_entrenamiento,coeficiente_determinacion_entrenamiento=get_metricas_modelo(model,x_entrenamiento,y_entrenamiento)\n",
    "    mse_validacion,coeficiente_determinacion_validacion=get_metricas_modelo(model,x_validacion,y_validacion)   \n",
    "\n",
    "    resultado=[str(index+1),str(capas),epochs,activacion,mse_entrenamiento,coeficiente_determinacion_entrenamiento,tiempo_entrenamiento,mse_validacion,coeficiente_determinacion_validacion]\n",
    "    resultados.append(resultado)  \n",
    "\n",
    "print(tabulate(resultados,headers=[\"Nombre\\nRed\",\"Capas\",\"Épocas\",\"Activación\",\"MSE\\nEntrenamiento\",\"R²\\nEntrenamiento\",\"Tiempo\\nEntrenamiento\",\"MSE\\nValidación\",\"R²\\nValidación\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
